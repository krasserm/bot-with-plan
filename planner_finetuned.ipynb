{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f16a25",
   "metadata": {},
   "source": [
    "# Planner fine-tuning on synthetic agent trajectories\n",
    "\n",
    "In a [previous article](https://github.com/krasserm/grammar-based-agents/blob/wip-article-2/example_agent.ipynb) I experimented with separating planning from function calling in [ReAct](https://arxiv.org/abs/2210.03629)-style LLM agents. A central planner module is responsible for describing the task for the next step and selecting an appropriate tool. The selected tool is responsible for translating the informal task description into tool-specific executable actions. Reducing the planner's responsibility to task formulation and tool selection only, without having to deal with function calling details, enables usage of smaller, less capable LLMs for planning. It also eases the generation of datasets for planner fine-tuning.\n",
    "\n",
    "This article first outlines how to generate a synthetic dataset for planner fine-tuning and how to fine-tune a 7B LLM to reach the performance of a GPT-4 based planner. To generate a synthetic dataset, we run an agent with a GPT-4 based planner in a simulation environment and record its trajectories. The interface to the environment is a set of simulated tools, instead of real ones. For example, a simulated `search_internet` tool, backed by GPT-4, generates search results from GPT-4's internal memory instead of actually searching the internet. \n",
    "\n",
    "For fine-tuning it is less important if observations are made in a simulation or a real environment. A planner has to learn to use these observations as-is, regardless whether they are hallucinated or not, and appropriately plan the next steps. The last part of this article runs the fine-tuned planner in a real environment, with a corresponding set of real tools as interface. The planner learns the available tools from the generated dataset so that they don't need to be specified in the prompt which can significantly reduce inference latencies. \n",
    "\n",
    "The predefined set of [simulated tools](simulation/tools) and their corresponding [real tools](gba/tools) used in this article are just examples and can be adjusted to whatever is needed for other applications. [Generating trajectories](simulation/README.md#generate-trajectories) in a simulation environment and [planner fine-tuning](train/README.md#planner-fine-tuning) with a different set of tools is straightforward with the framework provided by the [bot-with-plan](https://github.com/krasserm/bot-with-plan) project. The currently used tools are:\n",
    "\n",
    "| Tool name          | Tool description                                                                          |\n",
    "|--------------------|-------------------------------------------------------------------------------------------|\n",
    "| `ask_user`         | Useful for asking user about information missing in the request.                          |\n",
    "| `calculate_number` | Useful for numerical tasks that result in a single number.                                |\n",
    "| `create_event`     | Useful for adding a single entry to my calendar at given date and time.                   |\n",
    "| `search_wikipedia` | Useful for searching factual information in Wikipedia.                                    |\n",
    "| `search_internet`  | Useful for up-to-date information on the internet.                                        |\n",
    "| `send_email`       | Useful for sending an email to a single recipient.                                        |\n",
    "| `use_bash`         | Useful for executing commands in a Linux bash.                                            |\n",
    "| `final_answer`     | Useful for providing the final answer to a request. Must always be used in the last step. |\n",
    "\n",
    "The `final_answer` tool is a special tool used by the agent for providing a final answer to the user. Simulated tools `search_internet` and `search_wikipedia` report with a probability of 0.1 that they couldn't find an answer to the query or provide an incomplete answer. This is helpful to make the planner more robust to error conditions during fine-tuning. The [corresponding real tools](gba/tools/search) are fully-functional RAG-based search engines.\n",
    "\n",
    "## Dataset generation\n",
    "\n",
    "### Requests\n",
    "\n",
    "For running an [agent simulation](master/simulation), we first need to [generate](simulation/README.md#generate-requests) a set of requests i.e. questions and instructions that can be answered in one or more steps using a combination of available tools. Requests are generated with GPT-4 for a variety of topics. Overall, 2780 requests are generated. Examples include:\n",
    "\n",
    "- *Get the average Rotten Tomatoes scores for DreamWorks' last 5 movies.*\n",
    "- *Email me articles about the renovation of the Taj Mahal happening this year.*\n",
    "- *Compare the cost-per-click (CPC) and engagement rate of Snapchat ads to those of TikTok ads for the age group 18-24.*\n",
    "- *Give me the average time of men's 200m freestyle winners for the past three Olympics and how it compares to the all-time record.*\n",
    "- ...\n",
    "\n",
    "### Trajectories\n",
    "\n",
    "Trajectories for the 2780 training requests are [generated](simulation/README.md#generate-trajectories) by an agent with a GPT-4 based planner and the predefined set of GPT-4 based simulated tools. A request like *Get the average Rotten Tomatoes scores for DreamWorks' last 5 movies*, for example, may result in [this trajectory](docs/trajectory.json), with a revised plan at each step. Note how `thoughts` at each step may plan several steps ahead whereas `task` describes the very next step only. Forcing the planner to summarize previous steps and reason about missing information or actions further improves planning accuracy.\n",
    "\n",
    "### Quality filtering\n",
    "\n",
    "Low quality trajectories must be excluded from the final training dataset. For [rating](simulation/README.md#evaluate-trajectories) the quality of trajectories we ask GPT-4 to reflect on the steps and the final answer in the trajectory and assign ratings from 1 (poor) to 5 (excellent). Only trajectories with ratings 4 and 5 are accepted for the final training set.\n",
    "\n",
    "## Training dataset\n",
    "\n",
    "For each step in a trajectory a training example can be [generated](simulation/README.md#package-dataset). It contains the initial request, task-observations pairs from previous steps and the expected planner output for the next step. An example prompt is\n",
    "\n",
    "````\n",
    "User request: \n",
    "\n",
    "```\n",
    "Get the average Rotten Tomatoes scores for DreamWorks' last 5 movies. \n",
    "```\n",
    "\n",
    "Context information: \n",
    "\n",
    "```\n",
    "Task: Find the last 5 movies released by DreamWorks. \n",
    "Result: The last five movies released by DreamWorks are 'The Bad Guys' (2022), 'Boss Baby: Family Business' (2021), 'Trolls World Tour' (2020), 'Abominable' (2019), and 'How to Train Your Dragon: The Hidden World' (2019). \n",
    "\n",
    "Task: Search the internet for the Rotten Tomatoes score of 'The Bad Guys' (2022). \n",
    "Result: The Rotten Tomatoes score of 'The Bad Guys' (2022) is 88%. \n",
    "```\n",
    "\n",
    "Plan the next step.\n",
    "````\n",
    "\n",
    "The expected output is:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"context_information_summary\": \"The last five movies released by DreamWorks are 'The Bad Guys' (2022), 'Boss Baby: Family Business' (2021), 'Trolls World Tour' (2020), 'Abominable' (2019), and 'How to Train Your Dragon: The Hidden World' (2019). The Rotten Tomatoes score for 'The Bad Guys' (2022) is 88%.\", \n",
    "  \"thoughts\": \"Since the Rotten Tomatoes score for 'The Bad Guys' was found through an internet search, the same approach should be used to find the score for 'Boss Baby: Family Business' (2021).\", \n",
    "  \"task\": \"Search the internet for the Rotten Tomatoes score of 'Boss Baby: Family Business' (2021).\", \n",
    "  \"selected_tool\": \"search_internet\"\n",
    "}\n",
    "```\n",
    "\n",
    "After [filtering](simulation/README.md#package-dataset), we end up with a training set of 8579 examples. An important design decision was to omit the (static) set of available tools in the prompt and let the planner learn the available tools implicitly during fine-tuning. The advantage is a much shorter prompt and therefore lower inference latencies.\n",
    "\n",
    "## Planner fine-tuning\n",
    "\n",
    "The base model for [planner fine-tuning](train/README.md#planner-fine-tuning) is Mistral-7B-v0.1. It is trained for 3 epochs on the generated dataset with QLoRA using [autotrain-advanced](https://github.com/huggingface/autotrain-advanced), running locally. The loss is currently computed over the full sequence (prompt and completion) because the prompt contains a significant amount of planning-specific data which are task-observation pairs from the agent's current trajectory. After merging the adapters back into the base model, they are [converted](train/README.md#gguf-conversion-and-quantization) to GGUF, quantized to 8-bit and 4-bit and served on a llama.cpp server. \n",
    "\n",
    "## Planner evaluation\n",
    "\n",
    "The fine-tuned planners are [evaluated](simulation/README.md#planner-evaluation) in the simulation environment, together with the GPT-4 based planner and the zero-shot planner from the [previous article](https://github.com/krasserm/grammar-based-agents/blob/wip-article-2/example_agent.ipynb). Evaluation is done on a separate test set of 50 requests.\n",
    "\n",
    "| series          | pass_rate   | bad_task_rate | completion_rate |\n",
    "|:----------------|:-----------:|:-------------:|:---------------:|\n",
    "| zero-shot 8bit  | 0.72 ± 0.03 | 0.30 ± 0.02   | 0.88 ± 0.01     |\n",
    "| fine-tuned 4bit | 0.89 ± 0.02 | 0.14 ± 0.01   | 0.96 ± 0.01     |\n",
    "| fine-tuned 8bit | 0.88 ± 0.02 | 0.09 ± 0.01   | 0.95 ± 0.02     |\n",
    "| gpt-4           | 0.91 ± 0.03 | 0.07 ± 0.01   | 0.97 ± 0.01     |\n",
    "\n",
    "Basis for evaluation is the same rating procedure that has been used for filtering the training dataset. Evaluation metrics are pass rate, bad task rate and completion rate. \n",
    "\n",
    "- *pass rate* is defined as the fraction of requests that have been answered with a rating of 4 or higher.\n",
    "- *bad task rate* is the fraction of steps with a task description rating of 3 or lower. \n",
    "- *completion rate* is the number of requests that the agent could complete with a final answer in 10 steps or less.\n",
    "\n",
    "4 evaluation runs are executed for each planner to account for the non-deterministic behavior of simulated tools `search_internet` and `search_wikipedia`. These tools may decide with a probability of 0.1 to provide no answer or an incomplete answer. The mean and the standard error over 4 runs is reported in the table above.\n",
    "\n",
    "The pass rates of the fine-tuned planners (8-bit and 4-bit) are close to that of the GPT-4 based planner but significantly higher than that of the zero-shot planner. This doesn't say much about their efficiency though. A better metric for the efficiency is bad task rate. A higher number means longer and therefore less efficient trajectories. The 8-bit fine-tuned planner is close to the GPT-4 based planner and significantly better than the 4-bit quantized planner on this metric. Again, there is a large gap to the zero-shot planner. The completion rates of the fine-tuned planners and the GPT-4 based planner are similar with a large gap to the zero-shot planner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288681ed",
   "metadata": {},
   "source": [
    "## Real environment\n",
    "\n",
    "An agent configured with the fine-tuned planner can also solve complex user requests in a real environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a056b978-b909-487b-a20f-1f6f4543b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from gba.client import MistralInstruct, Llama3Instruct, LlamaCppClient\n",
    "\n",
    "# Proxy for 8-bit finetuned Mistral-7B-v0.1 planner\n",
    "mistral_finetuned = MistralInstruct(\n",
    "    llm=LlamaCppClient(url=\"http://localhost:8082/completion\", temperature=-1),\n",
    ")\n",
    "\n",
    "# Proxy for 8-bit quantized Llama-3-8B-Instruct\n",
    "llama3_instruct = Llama3Instruct(\n",
    "    llm=LlamaCppClient(url=\"http://localhost:8084/completion\", temperature=-1),\n",
    ")\n",
    "\n",
    "embedding_model = SentenceTransformer(\n",
    "    \"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "rerank_model = CrossEncoder(\n",
    "    \"mixedbread-ai/mxbai-rerank-large-v1\",\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "searxng_endopoint = \"http://localhost:8080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f6e2f0-547a-4a60-bb13-1418003d3eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading int8 search index...\n",
      "Loading document mapping...\n",
      "Loading binary search index...\n"
     ]
    }
   ],
   "source": [
    "from gba.agent import Agent\n",
    "from gba.client import ChatClient\n",
    "from gba.planner import FineTunedPlanner\n",
    "from gba.tools import *\n",
    "from gba.tools.functions import create_event, send_email\n",
    "\n",
    "\n",
    "search_wikipedia_tool = SearchWikipediaTool(\n",
    "    llm=llama3_instruct,\n",
    "    embedding_model=embedding_model,\n",
    "    rerank_model=rerank_model,                    \n",
    "    top_k_nodes=10,\n",
    "    top_k_related_documents=1,\n",
    "    top_k_related_nodes=3,\n",
    ")\n",
    "\n",
    "search_internet_tool = SearchInternetTool(\n",
    "    llm=llama3_instruct,\n",
    "    rerank_model=rerank_model,\n",
    "    searxng_endpoint=searxng_endopoint,\n",
    "    fetch_webpage_timeout=5.0,\n",
    "    top_k_documents=3,\n",
    "    top_k_nodes_per_document=5,\n",
    "    top_k_snippets=None,\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    AskTool(),\n",
    "    CalculateTool(model=llama3_instruct),\n",
    "    FunctionCallTool(model=llama3_instruct, fn=create_event),\n",
    "    FunctionCallTool(model=llama3_instruct, fn=send_email),\n",
    "    search_internet_tool,\n",
    "    search_wikipedia_tool,    \n",
    "    RespondTool(model=llama3_instruct),\n",
    "]\n",
    "\n",
    "client = ChatClient(model=mistral_finetuned)\n",
    "planner = FineTunedPlanner(client=client)\n",
    "agent = Agent(planner=planner, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a8732",
   "metadata": {},
   "source": [
    "Here's an example that uses the real tools `search_internet`, `create_request`, `ask_user` and `send_email`. The output shows the task, selected tool and the tool call result (observation) at each step. The `send_email` tool, defined as [application-specific function](gba/tools/functions.py), additionally outputs the generated email body. The return value of the agent's `run` method is the final answer to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf15598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Search for the dates of the next Olympic Winter Games.\n",
      "Tool: search_internet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching the internet for query 'next Olympic Winter Games dates'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: The next Olympic Winter Games, Milano Cortina 2026, will take place from February 6, 2026, to February 22, 2026.\n",
      "\n",
      "Task: Create a reminder for watching the Olympic Winter Games on February 8, 2026.\n",
      "Tool: create_event\n",
      "Observation: Event 'Olympic Winter Games' successfully added to calendar, date=2026-02-08, time=None\n",
      "\n",
      "Task: Ask the user for their friend's email address to send the invitation to watch the Olympic Winter Games together on TV.\n",
      "Tool: ask_user\n",
      "Observation: michael@example.com\n",
      "\n",
      "Task: Send an email to michael@example.com inviting him to watch the Olympic Winter Games together on TV on February 8, 2026.\n",
      "Tool: send_email\n",
      "Email body: Hi Michael, I'd love for you to join me in watching the Olympic Winter Games together on TV on February 8, 2026. The event starts at an unspecified time. Hope to see you then!\n",
      "Observation: Email sent to 'michael@example.com' with subject 'Join me to watch the Olympic Winter Games!'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A reminder has been created for the 3rd day of the next Olympic Winter Games, which is February 8, 2026, and an email invitation has been sent to michael@example.com to join me watching on TV.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"create a reminder on the 3rd day of the next olympic winter games \"\n",
    "          \"and invite my friend via email to join me watching on tv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfbf6b7",
   "metadata": {},
   "source": [
    "The next example uses the real tools `search_wikipedia` and `calculate_number` to answer a user question. The `calculate_number` tool additionally outputs the Python code generated to perform the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08dc1e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Search Wikipedia for the director of the movie Saving Private Ryan.\n",
      "Tool: search_wikipedia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching wikipedia for query 'Director of Saving Private Ryan'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: The director of the movie Saving Private Ryan is Steven Spielberg.\n",
      "\n",
      "Task: Search Wikipedia for the most successful movie directed by Steven Spielberg.\n",
      "Tool: search_wikipedia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching wikipedia for query 'most successful Steven Spielberg movie'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: Jurassic Park, during its release, grossed more than $914 million worldwide, becoming the most successful film released up to that time.\n",
      "\n",
      "Task: Search Wikipedia for the release date of the movie Saving Private Ryan.\n",
      "Tool: search_wikipedia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching wikipedia for query 'Saving Private Ryan release date'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: The movie Saving Private Ryan was released on July 24, 1998.\n",
      "\n",
      "Task: Calculate the time difference in years between June 11, 1993 (Jurassic Park release date) and July 24, 1998 (Saving Private Ryan release date).\n",
      "Tool: calculate_number\n",
      "```python\n",
      "from datetime import datetime\n",
      "jurassic_park_release_date = datetime(1993, 6, 11)\n",
      "saving_private_ryan_release_date = datetime(1998, 7, 24)\n",
      "time_difference = saving_private_ryan_release_date - jurassic_park_release_date\n",
      "result = time_difference.days / 365\n",
      "```\n",
      "Observation: 5.120547945205479\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The director of the movie Saving Private Ryan is Steven Spielberg, and his most successful movie is Jurassic Park, which was released in 1993, making it 5 years before Saving Private Ryan's release date.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"what is the name of the person who directed the movie Saving Private Ryan, \"\n",
    "          \"the most successful movie directed by this person and the time difference \"\n",
    "          \"in years between the release dates of the most successful movie and Saving \"\n",
    "          \"Private Ryan?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e43a0",
   "metadata": {},
   "source": [
    "It is interesting to see that the planner doesn't search for the release date of *Jurassic Park* but rather uses its internal knowledge to come up with the (correct) date of *June 11, 1993*. There is actually one training example that contains the Jurassic Park release date but in context of another request. It must be investigated if fine-tuning or base model pre-training causes the planner to leverage internal knowledge. In general, the fine-tuned planner has a strong tendency to lookup even trivial knowledge with search tools.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Fine-tuning a 7B LLM on synthetic trajectories from an agent simulation results in a planner with a performance comparable to a GPT-4 based planner when evaluated on a test set of requests in a simulation environment. A qualitative evaluation in a real environment demonstrates versatile tool usage for solving complex user requests.\n",
    "\n",
    "During fine-tuning, the planner learns available tools from the generated trajectories so that they don't need to be specified in the prompt which can significantly reduce inference latencies. The framework provided by the [bot-with-plan](https://github.com/krasserm/bot-with-plan) project can easily be adjusted to a different set of tools for specialization to other application domains.\n",
    "\n",
    "## Appendix\n",
    "\n",
    "### Further examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2b77c9-4220-41c6-907d-66052d2e1fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Search the internet for Leo DiCaprio's current girlfriend's name and age.\n",
      "Tool: search_internet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching the internet for query 'Leo DiCaprio current girlfriend name age'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: Leonardo DiCaprio's current girlfriend is Vittoria Ceretti.\n",
      "\n",
      "Task: Search the internet for Vittoria Ceretti's current age.\n",
      "Tool: search_internet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching the internet for query 'Vittoria Ceretti age'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: Vittoria Ceretti is 25 Years old.\n",
      "\n",
      "Task: Calculate the value of 25^0.24.\n",
      "Tool: calculate_number\n",
      "```python\n",
      "import math\n",
      "vittoria_age = 25\n",
      "result = pow(vittoria_age, 0.24)\n",
      "```\n",
      "Observation: 2.165237809112449\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Leo DiCaprio's current girlfriend, Vittoria Ceretti, is 25 years old and her age raised to the power of 0.24 is approximately 2.165237809112449.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"what is Leo DiCaprio's current girlfriend's age raised to the power of 0.24?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee0b227c-963d-44c6-aa2a-cedb72b94fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Search Wikipedia for the estimated year sharks first appeared on Earth.\n",
      "Tool: search_wikipedia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching wikipedia for query 'What is the estimated year sharks first appeared on Earth?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: According to the context, sharks first appeared on Earth around 450 million years ago during the Late Ordovician Period.\n",
      "\n",
      "Task: Search Wikipedia for the estimated year octopuses first appeared on Earth.\n",
      "Tool: search_wikipedia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching wikipedia for query 'What is the estimated year octopuses first appeared on Earth?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: The estimated year octopuses first appeared on Earth is over 470 million years ago.\n",
      "\n",
      "Task: Calculate the difference between 470 million years and 450 million years.\n",
      "Tool: calculate_number\n",
      "```python\n",
      "sharks_appeared = 450 * 10 ** 6\n",
      "octopuses_appeared = 470 * 10 ** 6\n",
      "result = octopuses_appeared - sharks_appeared\n",
      "```\n",
      "Observation: 20,000,000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sharks appeared on Earth around 450 million years ago, while octopuses first appeared over 20 million years earlier.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many years did sharks appear earlier on Earth, compared to octopuses?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3afb77b-4a5e-49d7-8e02-5a5b50b70f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Create an event titled 'Martin's Birthday Party' starting on December 17th at 8pm in 2023.\n",
      "Tool: create_event\n",
      "Observation: Event 'Martin's Birthday Party' successfully added to calendar, date=2023-12-17, time=20:00:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You're invited to Martin's Birthday Party on December 17th, 2023 at 8pm!\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Add Martin's birthday party, starting Dec. 17th 2023 8pm, to my calendar and respond with a one-line invitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819080f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: What is your wife's email address?\n",
      "Tool: ask_user\n",
      "Observation: birgit@example.com\n",
      "\n",
      "Task: What time and location are you planning to join your wife for the walk tomorrow in Vienna's biggest park?\n",
      "Tool: ask_user\n",
      "Observation: 3pm\n",
      "\n",
      "Task: What is the name of Vienna's biggest park?\n",
      "Tool: search_wikipedia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching wikipedia for query 'What is the name of Vienna's largest park?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: The name of Vienna's biggest park is the Prater.\n",
      "\n",
      "Task: Send an email to birgit@example.com inviting her to join you for a walk tomorrow at 3pm in Vienna's biggest park, which is called the Prater.\n",
      "Tool: send_email\n",
      "Email body: Hi Birgit,\n",
      "\n",
      "I'd love to invite you to join me for a walk in Vienna's biggest park, the Prater, tomorrow at 3pm. Let me know if you're interested.\n",
      "Best regards,\n",
      "Observation: Email sent to 'birgit@example.com' with subject 'Join me for a walk in the Prater tomorrow!'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I've sent an email to birgit@example.com inviting her to join me for a walk tomorrow at 3pm in Vienna's biggest park, the Prater.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"invite my wife via email joining me for a walk tomorrow in vienna's biggest park\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3545a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Search Wikipedia for the air date of the first episode of The Simpsons.\n",
      "Tool: search_wikipedia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching wikipedia for query 'What is the air date of the first episode of The Simpsons?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: The air date of the first episode of The Simpsons is December 17, 1989.\n",
      "\n",
      "Task: Calculate the age of The Simpsons by subtracting 1989 from the current year.\n",
      "Tool: calculate_number\n",
      "```python\n",
      "import datetime\n",
      "air_date_year = 1989\n",
      "current_year = datetime.datetime.now().year\n",
      "result = current_year - air_date_year\n",
      "```\n",
      "Observation: 35\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The first episode of The Simpsons aired on December 17, 1989, and the series is now 35 years old.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"when did the first episode of the Simpsons air and how old is the series now?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "406808f6-3399-4182-8f24-8d6438ba240c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you for asking!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How are you doing?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
